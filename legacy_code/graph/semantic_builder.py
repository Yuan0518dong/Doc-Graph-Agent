import os
import logging
import time
from pathlib import Path
from tqdm import tqdm
from neo4j import GraphDatabase
from sentence_transformers import SentenceTransformer

# ===  è·¯å¾„ä¸é…ç½® ===
CURRENT_DIR = Path(__file__).resolve().parent
PROJECT_ROOT = CURRENT_DIR.parent.parent

# === Neo4j é…ç½® ===
NEO4J_URI = "bolt://localhost:7687"
NEO4J_USER = "neo4j"
NEO4J_PASSWORD = "zyyzdy0518"

# === æ¨¡å‹é…ç½® (æœ¬åœ°å‘é‡æ¨¡å‹) ===
MODEL_NAME = 'all-MiniLM-L6-v2'  # è½»é‡çº§ï¼Œé€Ÿåº¦å¿«
BATCH_SIZE = 64

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')


class SemanticGraphBuilder:
    def __init__(self):
        self.driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))
        print(f"æ­£åœ¨åŠ è½½åµŒå…¥æ¨¡å‹ {MODEL_NAME} ...")
        self.model = SentenceTransformer(MODEL_NAME)
        print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")

    def close(self):
        self.driver.close()

    def create_vector_index(self):
        """åˆ›å»ºå‘é‡ç´¢å¼•ï¼Œè®©æœç´¢å˜å¿«"""
        with self.driver.session() as session:
            print("æ£€æŸ¥å‘é‡ç´¢å¼•...")
            session.run("""
                CREATE VECTOR INDEX chunk_embedding_index IF NOT EXISTS
                FOR (c:Chunk) ON (c.embedding)
                OPTIONS {indexConfig: {
                 `vector.dimensions`: 384,
                 `vector.similarity_function`: 'cosine'
                }}
            """)
            print("âœ… å‘é‡ç´¢å¼•å°±ç»ª")

    def build_embeddings(self):
        self.create_vector_index()

        with self.driver.session() as session:
            # 1. æ£€æŸ¥è¿˜æœ‰å¤šå°‘æ²¡è®¡ç®—å‘é‡çš„ Chunk
            count_query = "MATCH (c:Chunk) WHERE c.embedding IS NULL RETURN count(c)"
            total_remaining = session.run(count_query).single()[0]

            if total_remaining == 0:
                print("ğŸ‰ æ‰€æœ‰ Chunk éƒ½æœ‰å‘é‡äº†ï¼Œæ— éœ€å¤„ç†ã€‚")
                return

            print(f"[è¯­ä¹‰æ„å»º] å‘ç° {total_remaining} ä¸ªå¾…å¤„ç† Chunk")
            pbar = tqdm(total=total_remaining, desc="è®¡ç®—å‘é‡")

            while True:
                # 2. åˆ†æ‰¹è¯»å–
                fetch_query = """
                MATCH (c:Chunk) WHERE c.embedding IS NULL
                RETURN c.id AS id, c.text AS text
                LIMIT $limit
                """
                results = list(session.run(fetch_query, limit=BATCH_SIZE))
                if not results: break

                # 3. è®¡ç®—å‘é‡
                texts = [r["text"] for r in results]
                # è¿™é‡Œåšä¸ªç®€å•çš„é˜²é”™ï¼Œé˜²æ­¢ text ä¸ºç©º
                valid_texts = [t if t else "" for t in texts]
                embeddings = self.model.encode(valid_texts, show_progress_bar=False)

                # 4. æ‰¹é‡å†™å…¥
                update_query = """
                UNWIND $batches AS batch
                MATCH (c:Chunk {id: batch.id})
                SET c.embedding = batch.embedding
                """
                batches = [{"id": r["id"], "embedding": emb.tolist()} for r, emb in zip(results, embeddings)]
                session.run(update_query, batches=batches)

                pbar.update(len(results))

            pbar.close()
            print("\nğŸ‰ å‘é‡è®¡ç®—å®Œæˆï¼")


if __name__ == "__main__":
    builder = SemanticGraphBuilder()
    builder.build_embeddings()
    builder.close()