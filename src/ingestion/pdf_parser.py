import os
import time
import logging
from pathlib import Path
from concurrent.futures import ProcessPoolExecutor
from tqdm import tqdm
from docling.document_converter import DocumentConverter, PdfFormatOption
from docling.datamodel.pipeline_options import PdfPipelineOptions, AcceleratorOptions, AcceleratorDevice
from docling.datamodel.base_models import InputFormat

# === è·¯å¾„é…ç½® ===
CURRENT_DIR = Path(__file__).resolve().parent
PROJECT_ROOT = CURRENT_DIR.parent.parent
INPUT_DIR = PROJECT_ROOT / "data" / "raw"
OUTPUT_DIR = PROJECT_ROOT / "data" / "processed"

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')


def process_single_pdf(file_path):
    """
    å­è¿›ç¨‹ä»»åŠ¡
    """
    try:
        safe_name = file_path.stem
        output_file = OUTPUT_DIR / f"{safe_name}.md"

        # æ–­ç‚¹ç»­ä¼ 
        if output_file.exists() and output_file.stat().st_size > 100:
            return f"è·³è¿‡: {safe_name}"

        # === å…³é”®ä¿®æ”¹ï¼šå¼ºåˆ¶ä½¿ç”¨ CPU ===
        # 1. é…ç½®ç®¡é“é€‰é¡¹
        pipeline_options = PdfPipelineOptions()
        pipeline_options.do_ocr = True
        pipeline_options.do_table_structure = True
        pipeline_options.table_structure_options.do_cell_matching = True

        # å¼ºåˆ¶æŒ‡å®š CPU
        pipeline_options.accelerator_options = AcceleratorOptions(
            num_threads=4, device=AcceleratorDevice.CPU
        )

        # 2. åˆå§‹åŒ–è½¬æ¢å™¨
        converter = DocumentConverter(
            format_options={
                InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)
            }
        )

        # 3. æ‰§è¡Œè½¬æ¢
        result = converter.convert(file_path)
        md_content = result.document.export_to_markdown()

        with open(output_file, "w", encoding="utf-8") as f:
            f.write(md_content)

        return f"âœ… æˆåŠŸ: {safe_name}"

    except Exception as e:
        return f"å¤±è´¥: {file_path.name} - {str(e)[:100]}"


def main():
    if not OUTPUT_DIR.exists():
        OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    pdf_files = list(INPUT_DIR.glob("*.pdf"))
    total_files = len(pdf_files)

    if total_files == 0:
        print(f"è­¦å‘Š: è¿˜æ²¡ä¸‹è½½å®Œæˆ–è€…è·¯å¾„ä¸å¯¹ï¼Œæš‚æ—¶æ²¡æ‰¾åˆ° PDFã€‚")
        return

    print(f"å¾…å¤„ç†: {total_files} ç¯‡")

    # === å…³é”®ä¿®æ”¹ ===
    # ä½ çš„ CPU æ˜¯ 8 çº¿ç¨‹ï¼Œå†…å­˜ 16GBã€‚
    # å¼€ 4 ä¸ªè¿›ç¨‹æ¯”è¾ƒç¨³ï¼Œç•™ä¸€åŠèµ„æºç»™ç³»ç»Ÿï¼Œé˜²æ­¢å†…å­˜æº¢å‡ºæˆ–å¡æ­»ã€‚
    max_workers = 1

    print(f"å¯ç”¨è¿›ç¨‹æ•°: {max_workers} (å¹³è¡¡æ¨¡å¼)")

    start_time = time.time()

    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        results = list(tqdm(executor.map(process_single_pdf, pdf_files), total=total_files, unit="file"))

    # ç®€å•ç»Ÿè®¡
    success_count = sum(1 for r in results if "âœ…" in r)
    duration = time.time() - start_time

    print(f"\nğŸ‰ ä»»åŠ¡å®Œæˆï¼")
    print(f"è€—æ—¶: {duration / 3600:.2f} å°æ—¶")
    print(f"æˆåŠŸ: {success_count} / {total_files}")


if __name__ == "__main__":
    main()