import json
import os
import time
import re
from tqdm import tqdm
from neo4j import GraphDatabase
from openai import OpenAI

# === âš™ï¸ é…ç½®åŒºåŸŸ (DeepSeek R1 Local) ===
# 1. Neo4j é…ç½®
NEO4J_URI = "bolt://localhost:7687"
NEO4J_USER = "neo4j"
NEO4J_PASSWORD = "zyyzdy0518" # âœ… ä½ çš„å¯†ç 

# 2. Local LLM é…ç½® (Ollama)
API_KEY = "ollama"
BASE_URL = "http://localhost:11434/v1"
MODEL_NAME = "deepseek-r1:1.5b" # âœ… ä½ çš„æ¨¡å‹

class SemanticGraphBuilder:
    def __init__(self):
        self.driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))
        self.client = OpenAI(api_key=API_KEY, base_url=BASE_URL)

    def close(self):
        self.driver.close()

    def clean_deepseek_output(self, content: str) -> str:
        content = re.sub(r'<think>.*?</think>', '', content, flags=re.DOTALL)
        content = content.replace("```json", "").replace("```", "").strip()
        return content

    def extract_triples(self, text: str):
        if not text: return [] # é˜²å¾¡æ€§ç¼–ç¨‹ï¼šå¦‚æœæ˜¯ç©ºçš„ç›´æ¥è¿”å›

        prompt = f"""
        ä½ æ˜¯ä¸€ä¸ªçŸ¥è¯†å›¾è°±ä¸“å®¶ã€‚è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–å…³é”®å®ä½“å’Œå…³ç³»ã€‚
        æ–‡æœ¬:
        {text[:1200]} 
        è¦æ±‚:
        1. ä»…æå–æœ€é‡è¦çš„ 3-5 ä¸ªå…³ç³»ã€‚
        2. ç›´æ¥è¾“å‡º JSON æ•°æ®ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæˆ–æ€è€ƒè¿‡ç¨‹ã€‚
        3. å®ä½“ç±»å‹ (type) åªèƒ½æ˜¯: "Concept", "Method", "Metric", "Task"ã€‚
        4. å…³ç³» (relation) å¿…é¡»æ˜¯å¤§å†™è‹±æ–‡ï¼Œå¦‚: "USES", "IMPROVES", "SOLVES", "IS_A".
        è¾“å‡ºæ ¼å¼å¿…é¡»æ˜¯çº¯ JSON åˆ—è¡¨:
        [
            {{"head": "Transformer", "head_type": "Method", "relation": "REPLACES", "tail": "RNN", "tail_type": "Method"}}
        ]
        """
        try:
            response = self.client.chat.completions.create(
                model=MODEL_NAME,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.6,
            )
            raw_content = response.choices[0].message.content
            cleaned_content = self.clean_deepseek_output(raw_content)

            try:
                data = json.loads(cleaned_content)
            except json.JSONDecodeError:
                match = re.search(r'\[.*\]', cleaned_content, re.DOTALL)
                if match:
                    data = json.loads(match.group())
                else:
                    return []

            if isinstance(data, list):
                return data
            return data.get("triples", [])

        except Exception as e:
            # print(f"âš ï¸ æå–å¤±è´¥: {e}") # è¿™ä¸€è¡Œå¯ä»¥æ³¨é‡Šæ‰ï¼Œä¿æŒæ¸…çˆ½
            return []

    def build_semantics(self, limit=5):
        print(f"ğŸš€ å¼€å§‹è¯­ä¹‰æå– (Model: {MODEL_NAME}, Limit: {limit})...")
        print("ğŸ¢ DeepSeek R1 æ­£åœ¨æœ¬åœ°æ€è€ƒä¸­...")

        chunks_to_process = []
        with self.driver.session() as session:
            # âœ… å…³é”®ä¿®æ­£ç‚¹ï¼šè¿™é‡ŒåŸæ¥æ˜¯ c.textï¼Œç°åœ¨æ”¹æˆ c.content
            # åŒæ—¶ä¸ºäº†å…¼å®¹åé¢çš„ä»£ç ï¼Œæˆ‘ä»¬ç”¨ AS text æŠŠå®ƒåˆ«ååŒ–
            result = session.run(f"""
                MATCH (c:Chunk) 
                WHERE c.content IS NOT NULL
                RETURN c.id AS id, c.content AS text 
                LIMIT {limit}
            """)
            chunks_to_process = [record for record in result]

        print(f"ğŸ“Š é€‰ä¸­ {len(chunks_to_process)} ä¸ªåˆ‡ç‰‡...")

        with self.driver.session() as session:
            for record in tqdm(chunks_to_process, desc="Reasoning"):
                chunk_id = record["id"]
                text = record["text"]

                triples = self.extract_triples(text)
                if not triples: continue

                for triple in triples:
                    if "head" not in triple or "tail" not in triple: continue

                    session.run("""
                        MATCH (c:Chunk {id: $chunk_id})
                        MERGE (h:Entity {name: $head})
                        ON CREATE SET h.type = $head_type
                        MERGE (t:Entity {name: $tail})
                        ON CREATE SET t.type = $tail_type
                        MERGE (h)-[r:RELATED {type: $relation}]->(t)
                        MERGE (c)-[:HAS_ENTITY]->(h)
                        MERGE (c)-[:HAS_ENTITY]->(t)
                    """,
                    chunk_id=chunk_id,
                    head=triple["head"], head_type=triple.get("head_type", "Concept"),
                    tail=triple["tail"], tail_type=triple.get("tail_type", "Concept"),
                    relation=triple.get("relation", "RELATED")
                    )

        print("ğŸ‰ è¯­ä¹‰å¢å¼ºå®Œæˆï¼")

if __name__ == "__main__":
    builder = SemanticGraphBuilder()
    # âš ï¸ æ—¢ç„¶åˆšæ‰å·²ç»å¤±è´¥äº†ï¼Œè¿™æ¬¡å¯ä»¥å…ˆè·‘ 5 ä¸ªè¯•è¯•ï¼Œæˆ–è€…ç›´æ¥è·‘å®Œ
    builder.build_semantics(limit=20)
    builder.close()