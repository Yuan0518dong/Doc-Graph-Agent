import json
import os
from neo4j import GraphDatabase
from pathlib import Path
from tqdm import tqdm

# === é…ç½® ===
BASE_DIR = Path(__file__).resolve().parent.parent.parent
# ç¡®ä¿è¿™é‡Œè¯»å–çš„æ˜¯ markdown_splitter ç”Ÿæˆçš„é‚£ä¸ª jsonl
DATA_PATH = BASE_DIR / "data" / "processed" / "hierarchical_chunks.jsonl"

NEO4J_URI = "bolt://localhost:7687"
NEO4J_USER = "neo4j"
NEO4J_PASSWORD = "zyyzdy0518"  # âœ… ä½ çš„å¯†ç 


class KnowledgeGraphBuilder:
    def __init__(self):
        self.driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))

    def close(self):
        self.driver.close()

    def clean_graph(self):
        """æ¸…ç©ºæ•°æ®ï¼ˆä¸æ¸…ç©º Schemaï¼‰"""
        print("ðŸ§¹ æ­£åœ¨æ¸…ç©ºæ—§å›¾è°±æ•°æ®...")
        with self.driver.session() as session:
            session.run("MATCH (n) DETACH DELETE n")
        print("âœ… æ•°æ®åº“æ•°æ®å·²æ¸…ç©º")

    def init_schema(self):
        """åˆå§‹åŒ–çº¦æŸå’Œç´¢å¼• (ä½¿ç”¨ IF NOT EXISTS é˜²æ­¢æŠ¥é”™)"""
        print("âš™ï¸ æ­£åœ¨åˆå§‹åŒ– Schema (çº¦æŸä¸Žç´¢å¼•)...")
        with self.driver.session() as session:
            # 1. Document å”¯ä¸€æ€§çº¦æŸ
            # è¯­æ³•ï¼šå¦‚æžœä¸å­˜åœ¨æ‰åˆ›å»º
            session.run(
                "CREATE CONSTRAINT document_name_unique IF NOT EXISTS FOR (d:Document) REQUIRE d.name IS UNIQUE")

            # 2. Chunk å”¯ä¸€æ€§çº¦æŸ
            session.run("CREATE CONSTRAINT chunk_id_unique IF NOT EXISTS FOR (c:Chunk) REQUIRE c.id IS UNIQUE")

            # 3. Section è·¯å¾„ç´¢å¼• (åŠ é€ŸæŸ¥è¯¢)
            # è¿™å°±æ˜¯åˆšæ‰æŠ¥é”™çš„é‚£ä¸€è¡Œï¼ŒåŠ äº† IF NOT EXISTS å°±æ²¡äº‹äº†
            session.run("CREATE INDEX section_path_index IF NOT EXISTS FOR (s:Section) ON (s.full_path)")

            print("âœ… Schema åˆå§‹åŒ–å®Œæ¯• (è·³è¿‡äº†å·²å­˜åœ¨çš„è§„åˆ™)")

    def build_from_jsonl(self):
        """æ ¸å¿ƒæž„å»ºé€»è¾‘"""
        if not DATA_PATH.exists():
            print(f"âŒ æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶: {DATA_PATH}")
            return

        # 1. å…ˆæ¸…ç©ºæ•°æ®
        self.clean_graph()

        # 2. åˆå§‹åŒ– Schema (é˜²å¼¹ç‰ˆ)
        self.init_schema()

        print(f"ðŸš€ å¼€å§‹æž„å»ºå›¾è°±: {DATA_PATH.name}")

        # è¯»å–æ–‡ä»¶ç»Ÿè®¡è¡Œæ•°
        with open(DATA_PATH, "r", encoding="utf-8") as f:
            total_lines = sum(1 for _ in f)

        count = 0
        with open(DATA_PATH, "r", encoding="utf-8") as f:
            # ä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦æ¡
            for line in tqdm(f, total=total_lines, desc="Building Graph"):
                chunk = json.loads(line)
                metadata = chunk["metadata"]

                # æå–å…³é”®å­—æ®µ
                # å…¼å®¹ä¸åŒç‰ˆæœ¬çš„å­—æ®µå
                headers = metadata.get("headers", [])
                if not headers and "path" in metadata:
                    # å¦‚æžœæ²¡æœ‰ headers åˆ—è¡¨ï¼Œå°è¯•ä»Ž path å­—ç¬¦ä¸²è§£æž
                    headers = [h.strip() for h in metadata["path"].split(">") if h.strip() != "Root"]

                chunk_id = chunk["id"]
                content = chunk["content"]
                source_doc = metadata.get("source", "Unknown Doc")
                # æž„é€ ä¸€ä¸ªå…¨è·¯å¾„å­—ç¬¦ä¸²ç”¨äºŽç´¢å¼•
                path_str = " > ".join(headers)

                # æ‰§è¡Œå†™å…¥
                self._create_nodes(headers, content, chunk_id, source_doc, path_str)
                count += 1

        print(f"âœ… å›¾è°±æž„å»ºå®Œæˆï¼å…±å¤„ç† {count} ä¸ªåˆ‡ç‰‡ã€‚")

    def _create_nodes(self, headers, content, chunk_id, source_name, path_str):
        with self.driver.session() as session:
            # æˆ‘ä»¬æŠŠå¤æ‚é€»è¾‘æ‹†è§£ä¸º Python å¾ªçŽ¯ï¼Œè™½ç„¶æ¯”çº¯ Cypher æ…¢ä¸€ç‚¹ç‚¹ï¼Œä½†æžå…¶ç¨³å®šä¸å®¹æ˜“å†™é”™

            # 1. åˆ›å»º Document æ ¹èŠ‚ç‚¹
            session.run("MERGE (d:Document {name: $name})", name=source_name)

            # 2. å¾ªçŽ¯åˆ›å»º Section é“¾
            parent_label = "Document"
            parent_key = "name"
            parent_val = source_name

            # ç”¨äºŽç´¯ç§¯è·¯å¾„ï¼Œç¡®ä¿ Section å”¯ä¸€æ€§ (é¿å…ä¸åŒç« æœ‰ç›¸åŒçš„ "1.1 æ¦‚è¿°")
            current_full_path = source_name

            for h_title in headers:
                current_full_path += f" > {h_title}"

                # é“¾æŽ¥ Parent -> Current Section
                if parent_label == "Document":
                    q = """
                    MATCH (p:Document {name: $p_val})
                    MERGE (s:Section {full_path: $full_path})
                    SET s.title = $title, s.source = $doc_name
                    MERGE (p)-[:HAS_SECTION]->(s)
                    """
                    session.run(q, p_val=parent_val, full_path=current_full_path, title=h_title, doc_name=source_name)
                else:
                    q = """
                    MATCH (p:Section {full_path: $p_val})
                    MERGE (s:Section {full_path: $full_path})
                    SET s.title = $title, s.source = $doc_name
                    MERGE (p)-[:HAS_SUBSECTION]->(s)
                    """
                    session.run(q, p_val=parent_val, full_path=current_full_path, title=h_title, doc_name=source_name)

                # æ›´æ–°æŒ‡é’ˆ
                parent_label = "Section"
                parent_key = "full_path"
                parent_val = current_full_path

            # 3. æŒ‚è½½ Chunk
            # å¦‚æžœ headers ä¸ºç©ºï¼ˆåªæœ‰ Rootï¼‰ï¼Œç›´æŽ¥æŒ‚åœ¨ Document ä¸‹
            if not headers:
                q = """
                MATCH (d:Document {name: $doc_name})
                MERGE (c:Chunk {id: $c_id})
                SET c.content = $content, c.path = $path
                MERGE (d)-[:HAS_CHUNK]->(c)
                """
                session.run(q, doc_name=source_name, c_id=chunk_id, content=content, path=path_str)
            else:
                q = """
                MATCH (s:Section {full_path: $s_path})
                MERGE (c:Chunk {id: $c_id})
                SET c.content = $content, c.path = $path
                MERGE (s)-[:HAS_CHUNK]->(c)
                """
                session.run(q, s_path=current_full_path, c_id=chunk_id, content=content, path=path_str)


if __name__ == "__main__":
    builder = KnowledgeGraphBuilder()
    builder.build_from_jsonl()
    builder.close()