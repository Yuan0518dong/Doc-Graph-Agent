"""
(æœ€ç»ˆæé€Ÿç‰ˆ)ï¼šå¤šçº¿ç¨‹å¹¶å‘ + å¼ºåˆ¶æ‰“æ ‡ (é˜²æ­¢æ­»å¾ªç¯)
"""
import json
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
from neo4j import GraphDatabase
from openai import OpenAI

# === é…ç½®åŒºåŸŸ ===
NEO4J_URI = "bolt://localhost:7687"
NEO4J_USER = "neo4j"
NEO4J_PASSWORD = "zyyzdy0518"

API_KEY = "sk-5f460d116b4243f498d356b5fb052fa5"
BASE_URL = "https://api.deepseek.com"
MODEL_NAME = "deepseek-chat"
MAX_WORKERS = 5  # ä¿æŒ 5 ä¸ªçº¿ç¨‹å¹¶è¡Œ

class SemanticGraphBuilder:
    def __init__(self):
        self.driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))
        self.client = OpenAI(api_key=API_KEY, base_url=BASE_URL)

    def close(self):
        self.driver.close()

    def extract_triples(self, text: str):
        if not text or len(text) < 10: return []

        prompt = f"""
        è¯·ä»ä»¥ä¸‹æ–‡æœ¬æå–å®ä½“å…³ç³»ï¼ˆä¸‰å…ƒç»„ï¼‰ã€‚
        æ–‡æœ¬ï¼š{text[:1200]}
        
        è¦æ±‚ï¼š
        1. ä¸¥æ ¼è¾“å‡º JSON æ ¼å¼ï¼ŒåŒ…å« "triples" åˆ—è¡¨ã€‚
        2. å…³ç³» (relation) å¯ä»¥æ˜¯ä¸­æ–‡æˆ–è‹±æ–‡ã€‚
        
        è¾“å‡ºç¤ºä¾‹ï¼š
        {{
            "triples": [
                {{"head": "Transformer", "type": "æŠ€æœ¯", "relation": "replaces", "tail": "RNN", "tail_type": "æŠ€æœ¯"}}
            ]
        }}
        """

        try:
            response = self.client.chat.completions.create(
                model=MODEL_NAME,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªè¾“å‡º JSON çš„å·¥å…·ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                response_format={"type": "json_object"},
                temperature=0.1,
                timeout=60
            )
            raw_content = response.choices[0].message.content
            data = json.loads(raw_content)
            return data.get("triples", [])
        except Exception:
            return []

    def process_single_chunk(self, record):
        """å•ä¸ªä»»åŠ¡é€»è¾‘"""
        chunk_id = record["id"]
        text = record["text"]

        # 1. æå–
        triples = self.extract_triples(text)

        has_result = False

        # 2. å†™å…¥æ•°æ®åº“ (ç‹¬ç«‹ Session)
        with self.driver.session() as session:
            # ===  å…³é”®ä¿®æ­£ï¼šä¸ç®¡ triples æ˜¯ä¸æ˜¯ç©ºï¼Œå…ˆæ‰“ä¸Šæ ‡è®°ï¼===
            # è¿™æ ·ä¸‹æ¬¡è¿è¡Œï¼Œè¿™ä¸ª Chunk å°±ä¸ä¼šå†è¢«æŸ¥å‡ºæ¥çš„ã€‚
            session.run("MATCH (c:Chunk {id: $id}) SET c.entity_processed = true", id=chunk_id)

            if triples:
                has_result = True
                for t in triples:
                    if "head" not in t or "tail" not in t: continue

                    session.run("""
                        MATCH (c:Chunk {id: $chunk_id})
                        MERGE (h:Entity {name: $head})
                        ON CREATE SET h.type = $head_type
                        MERGE (t:Entity {name: $tail})
                        ON CREATE SET t.type = $tail_type
                        MERGE (h)-[r:RELATED {type: $relation}]->(t)
                        MERGE (c)-[:HAS_ENTITY]->(h)
                        MERGE (c)-[:HAS_ENTITY]->(t)
                    """,
                    chunk_id=chunk_id,
                    head=t["head"], head_type=t.get("type", "Concept"),
                    tail=t["tail"], tail_type=t.get("tail_type", "Concept"),
                    relation=t.get("relation", "RELATED")
                    )
        return has_result

    def build_semantics(self, limit=2000):
        print(f"å¯åŠ¨æé€Ÿæå– (çº¿ç¨‹: {MAX_WORKERS})...")

        chunks_to_process = []
        with self.driver.session() as session:
            # è¿™é‡Œçš„ WHERE æ¡ä»¶ä¿è¯äº†åªå¤„ç†æ²¡æ‰“æ ‡è®°çš„
            result = session.run(f"""
                MATCH (c:Chunk) 
                WHERE c.text IS NOT NULL 
                  AND c.entity_processed IS NULL
                RETURN c.id AS id, c.text AS text 
                LIMIT {limit}
                """)
            chunks_to_process = [record for record in result]

        total = len(chunks_to_process)
        if total == 0:
            print("ğŸ‰ æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆï¼")
            return

        print(f"å‰©ä½™ {total} ä¸ªåˆ‡ç‰‡ï¼Œå¼€å§‹å¤„ç†...")

        success_count = 0
        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            futures = [executor.submit(self.process_single_chunk, record) for record in chunks_to_process]

            for future in tqdm(as_completed(futures), total=total, desc="å¤„ç†è¿›åº¦"):
                try:
                    if future.result():
                        success_count += 1
                except Exception as e:
                    print(f"å¼‚å¸¸: {e}")

        print(f"\nâœ… æœ¬è½®ç»“æŸï¼æœ‰æ•ˆæå–: {success_count} ä¸ªã€‚")

if __name__ == "__main__":
    builder = SemanticGraphBuilder()
    builder.build_semantics()
    builder.close()