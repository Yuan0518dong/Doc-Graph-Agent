import json
from openai import OpenAI
import sys
import os

# ç¡®ä¿èƒ½æ‰¾åˆ° src.retrieval
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))
from src.retrieval.graph_engine import GraphRetriever

# === é…ç½® ===
API_KEY = "sk-5f460d116b4243f498d356b5fb052fa5"
BASE_URL = "https://api.deepseek.com"
MODEL_NAME = "deepseek-chat"


class GraphRAGAgent:
    def __init__(self):
        self.client = OpenAI(api_key=API_KEY, base_url=BASE_URL)
        self.retriever = GraphRetriever()

    def close(self):
        self.retriever.close()

    def extract_keywords(self, question: str) -> list:
        """
        åˆ©ç”¨ DeepSeek å°†è‡ªç„¶è¯­è¨€é—®é¢˜è½¬åŒ–ä¸ºæœç´¢å…³é”®è¯
        """
        prompt = f"""
        è¯·ä»ç”¨æˆ·çš„é—®é¢˜ä¸­æå– 2-3 ä¸ªæ ¸å¿ƒæœç´¢å…³é”®è¯ï¼ˆå®ä½“ï¼‰ã€‚
        é—®é¢˜ï¼š"{question}"

        è¦æ±‚ï¼š
        1. åªè¾“å‡ºå…³é”®è¯åˆ—è¡¨ï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡å­—ã€‚
        2. æ ¼å¼å¿…é¡»æ˜¯ JSON åˆ—è¡¨ï¼Œä¾‹å¦‚ï¼š["Transformer", "Attention", "Google"]
        """
        try:
            response = self.client.chat.completions.create(
                model=MODEL_NAME,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1
            )
            content = response.choices[0].message.content
            # ç®€å•çš„æ¸…æ´—é€»è¾‘
            content = content.replace("```json", "").replace("```", "").strip()
            keywords = json.loads(content)
            return keywords
        except Exception as e:
            print(f"âš ï¸ å…³é”®è¯æå–å¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨å¤‡ç”¨ç­–ç•¥ã€‚")
            return question.split()[:2]

    def chat(self, question: str):
        print(f"\nğŸ¤– ç”¨æˆ·æé—®: {question}")

        # 1. æ€è€ƒå…³é”®è¯
        keywords = self.extract_keywords(question)
        print(f"ğŸ” æ€è€ƒå‡ºçš„æœç´¢è¯: {keywords}")

        # 2. å»å›¾è°±é‡ŒæŠ“æ•°æ®
        context = self.retriever.query_graph_context(keywords, limit=5)

        if not context:
            print("âš ï¸ å›¾è°±é‡Œæ²¡æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ï¼Œä¾é æ¨¡å‹è‡ªå¸¦çŸ¥è¯†å›ç­”...")
            context = "æ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„èƒŒæ™¯çŸ¥è¯†ã€‚"
        else:
            # è¿™é‡Œçš„ replace æ˜¯ä¸ºäº†æ‰“å°ç¾è§‚ï¼Œå»æ‰è¿‡å¤šçš„æ¢è¡Œ
            print(f"ğŸ“š æˆåŠŸæ£€ç´¢åˆ°èƒŒæ™¯çŸ¥è¯† (å‰100å­—): {context[:100].replace(chr(10), ' ')}...")

        # 3. ç»“åˆä¸Šä¸‹æ–‡å›ç­”
        system_prompt = """
        ä½ æ˜¯ä¸€ä¸ªåŸºäºçŸ¥è¯†å›¾è°±çš„æ™ºèƒ½åŠ©æ‰‹ã€‚è¯·æ ¹æ®æä¾›çš„ã€èƒŒæ™¯çŸ¥è¯†ã€‘å›ç­”ç”¨æˆ·é—®é¢˜ã€‚
        å¦‚æœèƒŒæ™¯çŸ¥è¯†é‡Œæœ‰ç­”æ¡ˆï¼Œè¯·å¼•ç”¨å®ƒï¼›å¦‚æœæ²¡æœ‰ï¼Œè¯·è¯šå®åœ°è¯´ä¸çŸ¥é“ï¼Œæˆ–è€…ç”¨ä½ è‡ªå·±çš„çŸ¥è¯†è¡¥å……ï¼ˆä½†è¦è¯´æ˜ï¼‰ã€‚
        """

        user_prompt = f"""
        ã€èƒŒæ™¯çŸ¥è¯†ã€‘ï¼š
        {context}

        ã€ç”¨æˆ·é—®é¢˜ã€‘ï¼š
        {question}
        """

        print("âš¡ DeepSeek æ­£åœ¨ç»„ç»‡è¯­è¨€...")
        response = self.client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3,
            stream=True
        )

        full_response = ""
        print("\nğŸ’¬ å›ç­”:")
        for chunk in response:
            if chunk.choices[0].delta.content:
                content = chunk.choices[0].delta.content
                print(content, end="", flush=True)
                full_response += content
        print("\n" + "=" * 50)

        return full_response


# === æµ‹è¯•å…¥å£ ===
if __name__ == "__main__":
    agent = GraphRAGAgent()
    # æ—¢ç„¶ä½ æœ‰å¾ˆå¤šå…³äº Agent çš„æ–‡æ¡£ï¼Œæˆ‘ä»¬è¯•ä¸ªç›¸å…³çš„é—®é¢˜
    agent.chat("ä»€ä¹ˆæ˜¯æ™ºèƒ½ä½“ï¼ˆAgentï¼‰ï¼Ÿå®ƒå’Œæ™®é€šæ¨¡å‹æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ")
    agent.close()