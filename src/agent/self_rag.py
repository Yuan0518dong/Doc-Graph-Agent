"""
ä¼šåæ€çš„â€œå¤§è„‘â€ (The Orchestrator)
è¿™æ˜¯åŸºäº LangGraph æ„å»ºçš„çŠ¶æ€æœºï¼Œå®ƒå®šä¹‰äº†æ•´ä¸ªæ€è€ƒçš„é—­ç¯æµç¨‹

å®ƒçš„æ ¸å¿ƒé€»è¾‘ä¸å†æ˜¯ä¸€æ¡ç›´çº¿ï¼Œè€Œæ˜¯ä¸€ä¸ªæœ‰æ¡ä»¶çš„å¾ªç¯ï¼š
æ€è€ƒ (Agent Node): â€œç”¨æˆ·é—®äº† Transformerï¼Œæˆ‘è¦æŸ¥ä¸€ä¸‹ã€‚â€ -> ç”ŸæˆæŸ¥è¯¢æŒ‡ä»¤

æ‰§è¡Œ (Tool Node): è°ƒç”¨å·¥å…·ï¼ŒæŸ¥å›æ¥ä¸€æ®µæ–‡å­—

è´¨æ£€ (Calling Grader): (å…³é”®ç‚¹) è¿™é‡Œè°ƒç”¨äº† grader.py

æƒ…å†µ A (Pass): Grader è¯´ "yes"ã€‚ -> Agent æ‹¿ç€èµ„æ–™ç”Ÿæˆæœ€ç»ˆå›ç­” -> ç»“æŸ

æƒ…å†µ B (Fail): Grader è¯´ "no"ï¼ˆèµ„æ–™æ— å…³ï¼‰ã€‚ -> Agent è§¦å‘è‡ªæˆ‘ä¿®æ­£æœºåˆ¶ï¼šâ€œåˆšæ‰æŸ¥åäº†ï¼Œæˆ‘è¦æ¢ä¸ªå…³é”®è¯é‡æŸ¥ã€‚â€ -> å›åˆ°ç¬¬ 1 æ­¥ (Loop)

å®ƒèµ‹äºˆäº† AI â€œè‡ªæˆ‘çº é”™â€ çš„èƒ½åŠ›ã€‚å¦‚æœç¬¬ä¸€æ¬¡æ²¡æŸ¥å¯¹ï¼Œå®ƒä¸ä¼šçå›ç­”ï¼Œè€Œæ˜¯ä¼šå°è¯•ç¬¬äºŒæ¬¡ã€ç¬¬ä¸‰æ¬¡ï¼Œç›´åˆ°æ‰¾åˆ°æ­£ç¡®èµ„æ–™æˆ–è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°
"""
import json
import operator
from typing import Annotated, TypedDict

from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
memory = MemorySaver()
# å¼•å…¥ç»„ä»¶
from src.agent.tools import search_knowledge_base
from src.agent.grader import grade_document

# === é…ç½®å¤§è„‘ ===
llm = ChatOpenAI(
    base_url="http://localhost:11434/v1",
    api_key="ollama",
    model="qwen2.5:1.5b",
    temperature=0,
)

# === å®šä¹‰çŠ¶æ€ ===
class AgentState(TypedDict):
    """
    è¿™æ˜¯ä¸€ä¸ªåˆ—è¡¨ã€‚
    æƒ³è±¡å®ƒæ˜¯ä¸€ä¸ªå¾®ä¿¡èŠå¤©è®°å½•ã€‚
    Agent å¾€é‡Œé¢åŠ ä¸€æ¡ï¼ˆæ€è€ƒï¼‰ï¼ŒTool å¾€é‡Œé¢åŠ ä¸€æ¡ï¼ˆèµ„æ–™ï¼‰ï¼ŒGrader å¾€é‡Œé¢åŠ ä¸€æ¡ï¼ˆé€šçŸ¥ï¼‰ã€‚

    ä¸ºä»€ä¹ˆæˆ‘ä»¬è¦ç”¨ messages[-1]ï¼Ÿ å› ä¸ºæˆ‘ä»¬è¦çœ‹â€œæœ€æ–°é‚£æ¡æ¶ˆæ¯â€ã€‚
    """
    messages: Annotated[list[BaseMessage], operator.add] #é‡åˆ°å¤šä¸ª messagesï¼Œè¯·ä½¿ç”¨ + æ¥åˆå¹¶ï¼Œè€Œä¸æ˜¯è¦†ç›–
    loop_count: int # é˜²æ­¢æ­»å¾ªç¯

# === èŠ‚ç‚¹ 1: æ€è€ƒè€… (Agent) ===
def agent_node(state: AgentState):
    """
    è¿™æ˜¯å¤§è„‘å†³ç­–ä¸­å¿ƒï¼Œè´Ÿè´£"å˜è„¸"ï¼ˆåˆ‡æ¢æ¨¡å¼ï¼‰
    [æ¨¡å¼åˆ‡æ¢é€»è¾‘]:
    æ£€æŸ¥å†å²æ¶ˆæ¯ï¼šçœ‹æœ€åä¸€æ¡æ˜¯ä¸æ˜¯ Grader å‘å›æ¥çš„"èµ„æ–™æœ‰æ•ˆ"é€šçŸ¥
    æ¨¡å¼ A (æœæŸ¥å®˜æ¨¡å¼):
       - è§¦å‘æ¡ä»¶ï¼šè¿˜æ²¡æŸ¥èµ„æ–™ï¼Œæˆ–è€… Grader è¯´"NO"ï¼ˆèµ„æ–™æ— æ•ˆï¼‰ã€‚
       - åŠ¨ä½œï¼šå¿…é¡»è¾“å‡º JSON {"action": "search"} å»è°ƒç”¨å·¥å…·ï¼Œä¸å‡†ç›´æ¥å›ç­”
    æ¨¡å¼ B (ä½œå®¶æ¨¡å¼):
       - è§¦å‘æ¡ä»¶ï¼šGrader åˆšæ‰è¯´äº†"YES"ï¼ˆèµ„æ–™æœ‰æ•ˆï¼‰ã€‚
       - åŠ¨ä½œï¼šç¦æ­¢å†æŸ¥èµ„æ–™ï¼ä¸¥ç¦è¾“å‡º JSONï¼ç›´æ¥æ ¹æ®æ‰‹å¤´çš„èµ„æ–™å†™å‡ºæœ€ç»ˆç­”æ¡ˆ
    """
    messages = state["messages"]
    loop_count = state.get("loop_count", 0)

    # === ä¿®æ­£åçš„ä¾¦æ¢é€»è¾‘ ===
    # æˆ‘ä»¬ä¸ä»…è¦çœ‹æœ‰æ²¡æœ‰"èµ„æ–™æœ‰æ•ˆ"ï¼Œè¿˜è¦çœ‹å®ƒæ˜¯ä¸æ˜¯"æ–°é²œ"çš„
    has_valid_context = False
    last_msg = messages[-1]

    # é€»è¾‘ Aï¼šåˆšæŸ¥å®Œèµ„æ–™ -> ä½œå®¶æ¨¡å¼
    if isinstance(last_msg, HumanMessage) and "ã€ç³»ç»Ÿé€šçŸ¥ã€‘ï¼šèµ„æ–™æœ‰æ•ˆ" in last_msg.content:
        has_valid_context = True
    # é€»è¾‘ Bï¼šç”¨æˆ·å‘äº†æ–°é—®é¢˜ -> æœæŸ¥å®˜æ¨¡å¼ (å¼ºåˆ¶é‡ç½®)
    elif isinstance(last_msg, HumanMessage) and "ã€ç³»ç»Ÿé€šçŸ¥ã€‘" not in last_msg.content:
        has_valid_context = False


    # === åŠ¨æ€å˜è„¸é€»è¾‘ ===
    if has_valid_context:
        # ã€æ¨¡å¼ Bï¼šä½œå®¶æ¨¡å¼ã€‘
        sys_prompt_content = """
                ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯ä¸“å®¶ã€‚èµ„æ–™åº“æ£€ç´¢å·²å®Œæˆã€‚
                ä»»åŠ¡ï¼šæ ¹æ®èµ„æ–™å›ç­”é—®é¢˜ã€‚
                 é‡ç‚¹ï¼šå¿½ç•¥å®éªŒæ•°æ®è¡¨æ ¼ï¼Œä¸“æ³¨äºè§£é‡Šã€ç®—æ³•åŸç†ã€‘å’Œã€æ¶æ„è®¾è®¡ã€‘ã€‚
                """
        # ä½œå®¶æ¨¡å¼ä¸éœ€è¦ä¿®æ”¹ç”¨æˆ·æ¶ˆæ¯
        final_messages = [SystemMessage(content=sys_prompt_content)] + messages

    else:
        # ã€æ¨¡å¼ Aï¼šæœæŸ¥å®˜æ¨¡å¼ã€‘
        sys_prompt_content = """
                ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨çš„ç ”ç©¶å‘˜ã€‚
                1. é‡åˆ°é—®é¢˜ï¼Œ**å¿…é¡»**å…ˆè°ƒç”¨æœç´¢å·¥å…·ã€‚
                2. æ ¼å¼ï¼š{"action": "search", "query": "å…³é”®è¯"}
                """

        # === æ ¸å¿ƒä¿®å¤ï¼šæœ«å°¾å¼ºæŒ‡ä»¤ (Suffix Prompt) ===
        # 1.5B æ¨¡å‹è®°æ€§ä¸å¥½ï¼Œå¿…é¡»åœ¨æœ€åä¸€å¥ç‹ ç‹ è¸¢å®ƒä¸€è„š
        # æˆ‘ä»¬å¤åˆ¶ä¸€ä»½æ¶ˆæ¯åˆ—è¡¨ï¼Œä»¥å…æ±¡æŸ“åŸå§‹çŠ¶æ€
        final_messages = messages.copy()

        # æ‰¾åˆ°æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
        if isinstance(final_messages[-1], HumanMessage):
            original_text = final_messages[-1].content
            # åªæœ‰å½“å®ƒè¿˜æ²¡è¢«ä¿®æ”¹è¿‡æ—¶ï¼Œæ‰è¿½åŠ æŒ‡ä»¤
            if "ç³»ç»Ÿå¼ºåˆ¶è¦æ±‚" not in original_text:
                forced_instruction = f"""
                        {original_text}

                        (ç³»ç»Ÿå¼ºåˆ¶è¦æ±‚ï¼šè¿™æ˜¯ä¸€ä¸ªæŠ€æœ¯ç»†èŠ‚é—®é¢˜ï¼Œä½ ç°åœ¨çš„çŸ¥è¯†åº“æ˜¯ç©ºçš„ã€‚
                        ä½ **å¿…é¡»**å…ˆè¾“å‡º JSON è°ƒç”¨å·¥å…·æŸ¥è¯¢ï¼Œ**ä¸¥ç¦**ç›´æ¥å‡­è®°å¿†å›ç­”ï¼
                        æ ¼å¼ç¤ºä¾‹ï¼š{{"action": "search", "query": "Transformer vs RNN advantages"}})
                        """
                final_messages[-1] = HumanMessage(content=forced_instruction)

        final_messages = [SystemMessage(content=sys_prompt_content)] + final_messages

    print(f"[Agent] ç¬¬ {loop_count + 1} æ¬¡æ€è€ƒ (æ¨¡å¼: {'ä½œå®¶' if has_valid_context else 'æœæŸ¥å®˜'})...")

    # ä½¿ç”¨å¤„ç†è¿‡çš„ final_messages è°ƒç”¨æ¨¡å‹
    response = llm.invoke(final_messages)

    print(f"[Agent Output]: {response.content[:50]}...")

    return {"messages": [response], "loop_count": loop_count}

# === èŠ‚ç‚¹ 2: è·¯ç”± (Router) ===
def router_node(state: AgentState):
    """
    è¿™ä¸ªèŠ‚ç‚¹æ˜¯è·¯ç”±å¯¼èˆª
    å¦‚æœAgentè¾“å‡ºçš„JSONæ ¼å¼çš„å†…å®¹ï¼Œåˆ™ä¼šæ”¾è¡Œå»toolsèŠ‚ç‚¹
    å¦åˆ™ä¼šç›´æ¥ç»“æŸ
    Agent -> Router -> (Tools OR End)
    Tools -> Agent (è¿™å°±æ„æˆäº†ç¯)
    """
    last_msg = state["messages"][-1]
    content = last_msg.content.strip()

    try:
        # 1. å°è¯•å¯»æ‰¾ JSON çš„å¤§æ‹¬å·èŒƒå›´
        start = content.find('{')
        end = content.rfind('}') + 1

        # 2. å¦‚æœæ‰¾åˆ°äº†æ‹¬å·ï¼Œå°è¯•è§£æ
        if start != -1 and end != -1:
            json_str = content[start:end]
            data = json.loads(json_str)

            # 3. æ£€æŸ¥å­—æ®µæ˜¯å¦åŒ¹é…
            # åªè¦æœ‰ action ä¸”æ˜¯ searchï¼Œå°±æ”¾è¡Œ
            if data.get("action") == "search":
                return "tools"

    except Exception as e:
        print(f"[Router] JSON è§£æå¤±è´¥: {e}")

    # æ²¡æŠ“åˆ°æŒ‡ä»¤ï¼Œæˆ–è€…æŒ‡ä»¤ä¸å¯¹ï¼Œå°±ç»“æŸ
    return END

# === èŠ‚ç‚¹ 3: æ‰§è¡Œä¸åæ€ (Tool + Grader) ===
def tool_and_grade_node(state: AgentState):
    """
    è¿™æ˜¯"æ‰‹"å’Œ"è´¨æ£€å‘˜"çš„ç»“åˆä½“ã€‚
    1. æ‰§è¡Œ: è°ƒç”¨ search_knowledge_base å·¥å…·çœŸæ­£å»æŸ¥ Neo4j/Chromaã€‚
    2. è´¨æ£€: é©¬ä¸Šè°ƒç”¨ grade_document æ£€æŸ¥æŸ¥å›æ¥çš„èµ„æ–™å¯¹ä¸å¯¹

    [æµç¨‹åˆ†æ”¯]:
    - æƒ…å†µ A (YES): èµ„æ–™æœ‰ç”¨ -> å‘Šè¯‰ Agent "èµ„æ–™é½äº†ï¼Œè¯·å›ç­”"ã€‚
    - æƒ…å†µ B (NO):  èµ„æ–™åƒåœ¾ -> å‘Šè¯‰ Agent (æ³¨æ„æ˜¯å›ç»™å¤§è„‘!) "æŸ¥åäº†ï¼Œè¯·æ¢ä¸ªå…³é”®è¯é‡æŸ¥"
    """
    messages = state["messages"]
    last_msg = messages[-1]
    loop_count = state.get("loop_count", 0)

    # 1. è§£ææŸ¥è¯¢è¯
    try:
        content = last_msg.content
        start = content.find('{')
        end = content.rfind('}') + 1
        data = json.loads(content[start:end])
        query = data["query"]

        print(f"[Tool] æ‰§è¡Œæœç´¢: {query}")
        doc_content = search_knowledge_base.invoke(query)

        # 2. è·å–åŸå§‹é—®é¢˜
        # å‡è®¾å€’æ•°ç¬¬2æ¡æ˜¯ User çš„é—®é¢˜ï¼ˆåœ¨ Agent å›å¤ä¹‹å‰ï¼‰
        # è¿™é‡Œä¸ºäº†ç®€ä¾¿ï¼Œæˆ‘ä»¬éå†æ‰¾åˆ°æœ€æ–°çš„ HumanMessage
        user_question = "Unknown"
        for m in reversed(messages):
            if isinstance(m, HumanMessage) and "ã€ç³»ç»Ÿé€šçŸ¥ã€‘" not in m.content:
                user_question = m.content
                break

        # 3. Grader ä»‹å…¥è´¨æ£€
        score = grade_document(user_question, doc_content)

        if score == "yes":
            print("[Grader] èµ„æ–™ç›¸å…³ï¼é€šè¿‡ï¼")
            return {
                "messages": [HumanMessage(content=f"ã€ç³»ç»Ÿé€šçŸ¥ã€‘ï¼šèµ„æ–™æœ‰æ•ˆã€‚\nå†…å®¹ï¼š{doc_content}\n\nè¯·å›ç­”ã€‚")],
                "loop_count": loop_count +1
            }
        else:
            print("[Grader] èµ„æ–™æ— å…³ï¼æ‰“å›é‡å†™ï¼")
            # å¢åŠ è®¡æ•°ï¼Œé˜²æ­¢æ­»å¾ªç¯
            # å¦‚æœé‡è¯•è¶…è¿‡ 2 æ¬¡ (ä» 0 å¼€å§‹è®¡æ•°ï¼Œæ‰€ä»¥æ˜¯ 0, 1, 2)
            if loop_count >= 2:
                print("[System] é‡è¯•æ¬¡æ•°è¿‡å¤šï¼Œå¼ºåˆ¶ç†”æ–­ï¼è¦æ±‚ Agent å¼ºè¡Œå›ç­”ã€‚")

                # è¿™æ˜¯ä¸€ä¸ª"æ¬ºéª—"æŒ‡ä»¤ï¼šå‘Šè¯‰ Agent èµ„æ–™å…¶å®æ˜¯æœ‰çš„ï¼Œé€¼å®ƒå›ç­”
                # è¿™æ ·å¯ä»¥æ‰“ç ´"å¿…é¡»æŸ¥å·¥å…·"çš„æ­»å¾ªç¯
                forced_instruction = f"""
                                ã€ç³»ç»Ÿé€šçŸ¥ã€‘ï¼šè™½ç„¶èµ„æ–™å¯èƒ½ä¸å®Œç¾ï¼Œä½†é‡è¯•æ¬¡æ•°å·²è¾¾ä¸Šé™ã€‚
                                è¯·å¿½ç•¥"å¿…é¡»æŸ¥å·¥å…·"çš„æŒ‡ä»¤ã€‚
                                è¯·æ ¹æ®ä»¥ä¸‹ç°æœ‰ä¿¡æ¯ï¼ˆæˆ–ä½ è‡ªå·±çš„çŸ¥è¯†ï¼‰ç›´æ¥å›ç­”é—®é¢˜ï¼š"{user_question}"
                                """
                return {
                    "messages": [HumanMessage(content=forced_instruction)],
                    "loop_count": loop_count + 1
                }

            return {
                "messages": [HumanMessage(
                    content=f"ã€ç³»ç»Ÿé€šçŸ¥ã€‘ï¼šä½ æœç´¢çš„ '{query}' ç»“æœä¸é—®é¢˜æ— å…³ã€‚\nè¯·**æ›´æ¢å…³é”®è¯**é‡æ–°å°è¯•æœç´¢ã€‚")],
                "loop_count": loop_count + 1
            }

    except Exception as e:
        return {"messages": [HumanMessage(content=f"å·¥å…·è°ƒç”¨é”™è¯¯: {e}")]}

# === æ„å»ºå›¾è°± LangGraph===
workflow = StateGraph(AgentState)

workflow.add_node("agent",agent_node)
workflow.add_node("tools_grader",tool_and_grade_node)

workflow.set_entry_point("agent")

# ä¼ å…¥ "agent" èŠ‚ç‚¹çš„è¾“å‡º
# ç”¨ router_node åˆ¤æ–­
# æ ¹æ®è¿”å›å€¼å†³å®šè·¯å¾„
workflow.add_conditional_edges(
    "agent",
    router_node,
    {
        "tools": "tools_grader",
        END: END
    }
)

# æ ¸å¿ƒé—­ç¯ï¼šå·¥å…·æ‰§è¡Œå®Œ -> å›åˆ° Agent æ ¹æ®åé¦ˆå†³å®šæ˜¯"é‡æŸ¥"è¿˜æ˜¯"å›ç­”"
# tools_grader æ‰§è¡Œå®Œåï¼Œå›åˆ° agent å†æ€è€ƒä¸€æ¬¡
workflow.add_edge("tools_grader", "agent")

app = workflow.compile(checkpointer=memory)

# === è¿è¡Œ ===
if __name__ == "__main__":
    print("ğŸš€ å¯åŠ¨ Self-RAG Agent (å¤šè½®å¯¹è¯ + è®°å¿†ç‰ˆ)...")

    # === 1. é…ç½®è®°å¿†çº¿ç¨‹ ===
    # thread_id å°±æ˜¯ç”¨æˆ·çš„èº«ä»½è¯ï¼Œåªè¦ ID ä¸å˜ï¼Œè®°å¿†å°±åœ¨
    thread_id = "user_test_007"

    # æˆ‘ä»¬æŠŠ recursion_limit (é˜²æ­¢æ­»å¾ªç¯) å’Œ configurable (è®°å¿†ID) åˆå¹¶åˆ°ä¸€ä¸ª config é‡Œ
    run_config = {
        "configurable": {"thread_id": thread_id},
        "recursion_limit": 15  # ç»™è¶³å¤Ÿå¤šçš„é‡è¯•æœºä¼š
    }

    # === Round 1: æµ‹è¯• Prompt è°ƒä¼˜ (æ˜¯å¦èƒ½ç­”å‡ºåŸç†) ===
    q1 = "Transformer çš„æ ¸å¿ƒæœºåˆ¶æ˜¯ä»€ä¹ˆï¼Ÿ"
    print(f"\nğŸ—£ï¸ User (Q1): {q1}")

    input1 = {"messages": [HumanMessage(content=q1)], "loop_count": 0}
    final_state1 = app.invoke(input1, config=run_config)

    print(f"ğŸ¤– Agent (A1): {final_state1['messages'][-1].content}")

    # === Round 2: æµ‹è¯• Memory (æ˜¯å¦è®°å¾—'å®ƒ'æ˜¯è°) ===
    # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬åªè¯´"å®ƒ"ï¼Œå¦‚æœ Agent èƒ½å›ç­”å‡º Transformer çš„ä¼˜ç‚¹ï¼Œè¯´æ˜è®°å¿†ç”Ÿæ•ˆäº†
    q2 = "å®ƒç›¸æ¯” RNN æœ‰ä»€ä¹ˆä¸»è¦ä¼˜åŠ¿ï¼Ÿ"
    print(f"\nğŸ—£ï¸ User (Q2): {q2}")

    input2 = {"messages": [HumanMessage(content=q2)], "loop_count": 0}
    final_state2 = app.invoke(input2, config=run_config)

    print(f"ğŸ¤– Agent (A2): {final_state2['messages'][-1].content}")


















